---
title: 遇到的坑
tags: 
notebook: spark
---

[TOC]


# 坑

## 在idea中打jar包
[参考](http://blog.csdn.net/qq1010885678/article/details/45954731)
不要在 setmaster("local") 后打包提交到集群,会报错

## 本地跑spark + mysql 出现 not found driver错误

MySQL的驱动不在sparkclass中, 本地运行在idea中加入mysql-jdbc的jar包,yarn运行则将jar包以spark-submit 提交到集群

## spark读取数据库数据显示乱码

参考[这篇文章](http://blog.csdn.net/qq_14950717/article/details/51511150)

其实就是在链接MySQL的时候指定编码方式

``` text
进入spark-shell， 输入System.getProperty("file.encoding")，返回”ISO-8859-1“，说明它的默认编码方式是ISO-8859-1。
```

如果是读取的文件,参考[这篇文章](http://blog.csdn.net/Amber_amber/article/details/50036779)

在从mysql中读取数据（包含字段值问中文）

例如当使用使用`select id from test where name =’杨’`的时候出现了错误，结果为零

``` scala
object sparksql {
def main(args: Array[String]) {
val sc = new SparkContext( new SparkConf().setAppName(“sparksql”))

val sqlContext = new SQLContext( sc )
val url="jdbc:mysql://192.168.0.66:3306/test"
val prop = new Properties()
prop.setProperty("user","root")
prop.setProperty("password","1q2w3e4r")
//加入这两个属性  解决问题
prop.setProperty("useUnicode","true")
prop.setProperty("characterEncoding","utf8")
```

